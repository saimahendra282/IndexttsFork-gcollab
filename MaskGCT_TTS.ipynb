{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Credit:\n",
        "[MaskGCT GitHub](https://github.com/open-mmlab/Amphion/tree/main/models/tts/maskgct)"
      ],
      "metadata": {
        "id": "SMR867ZiAb2c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLskI67FihE9"
      },
      "outputs": [],
      "source": [
        "base_path=\"/content\"\n",
        "# base_path=\".\" #for  local devices"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install MaskGCT TTS and Restart Session [Cancel All Pop-Up] [Wait For 6 Minutes]\n",
        "!rm -rf $base_path/Amphion\n",
        "%cd $base_path\n",
        "# !git clone https://github.com/open-mmlab/Amphion.git\n",
        "!git clone https://github.com/NeuralFalconYT/Amphion\n",
        "!pip install setuptools ruamel.yaml tqdm\n",
        "# pip install tensorboard tensorboardX torch==2.0.1\n",
        "!pip install transformers===4.41.1\n",
        "!pip install -U encodec\n",
        "!pip install black==24.1.1\n",
        "!pip install oss2\n",
        "!sudo apt-get install espeak-ng\n",
        "!pip install phonemizer\n",
        "!pip install g2p_en\n",
        "!pip install accelerate==0.31.0\n",
        "!pip install funasr zhconv zhon modelscope\n",
        "# pip install git+https://github.com/lhotse-speech/lhotse\n",
        "!pip install timm\n",
        "!pip install jieba cn2an\n",
        "!pip install unidecode\n",
        "!pip install -U cos-python-sdk-v5\n",
        "!pip install pypinyin\n",
        "!pip install jiwer\n",
        "!pip install omegaconf\n",
        "!pip install pyworld\n",
        "!pip install py3langid==0.2.2 LangSegment\n",
        "# !pip install onnxruntime\n",
        "!pip install onnxruntime-gpu==1.20.0\n",
        "!pip install pyopenjtalk\n",
        "!pip install pykakasi\n",
        "!pip install -U openai-whisper\n",
        "!pip install json5\n",
        "!pip install pydub\n",
        "!pip install gradio\n",
        "# !pip install nltk\n",
        "!pip install nltk==3.8.1\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import time\n",
        "time.sleep(5)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uvOlgRb-klej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After auto-restarting the session, run from the next cell."
      ],
      "metadata": {
        "id": "hWwe4qauAK8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path=\"/content\"\n",
        "# base_path=\".\" #for  local devices\n",
        "project_path=f\"{base_path}/Amphion/\""
      ],
      "metadata": {
        "id": "O5EQ4XeSjTpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Model\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "import subprocess\n",
        "import torch\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "import uuid\n",
        "import re\n",
        "from huggingface_hub import hf_hub_download\n",
        "semantic_code_ckpt,codec_encoder_ckpt,codec_decoder_ckpt,t2s_model_ckpt,s2a_1layer_ckpt,s2a_full_ckpt=None,None,None,None,None,None\n",
        "def download_checkpoint():\n",
        "  # download checkpoint\n",
        "  global semantic_code_ckpt,codec_encoder_ckpt,codec_decoder_ckpt,t2s_model_ckpt,s2a_1layer_ckpt,s2a_full_ckpt\n",
        "  # download semantic codec ckpt\n",
        "  semantic_code_ckpt = hf_hub_download(\n",
        "      \"amphion/MaskGCT\", filename=\"semantic_codec/model.safetensors\"\n",
        "  )\n",
        "  # download acoustic codec ckpt\n",
        "  codec_encoder_ckpt = hf_hub_download(\n",
        "      \"amphion/MaskGCT\", filename=\"acoustic_codec/model.safetensors\"\n",
        "  )\n",
        "  codec_decoder_ckpt = hf_hub_download(\n",
        "      \"amphion/MaskGCT\", filename=\"acoustic_codec/model_1.safetensors\"\n",
        "  )\n",
        "  # download t2s model ckpt\n",
        "  t2s_model_ckpt = hf_hub_download(\n",
        "      \"amphion/MaskGCT\", filename=\"t2s_model/model.safetensors\"\n",
        "  )\n",
        "  # download s2a model ckpt\n",
        "  s2a_1layer_ckpt = hf_hub_download(\n",
        "      \"amphion/MaskGCT\", filename=\"s2a_model/s2a_model_1layer/model.safetensors\"\n",
        "  )\n",
        "  s2a_full_ckpt = hf_hub_download(\n",
        "      \"amphion/MaskGCT\", filename=\"s2a_model/s2a_model_full/model.safetensors\"\n",
        "  )\n",
        "download_checkpoint()\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pOX_-UHSFdwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Utils\n",
        "\n",
        "def get_max_gpu_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda:0\")\n",
        "        total_memory = torch.cuda.get_device_properties(device).total_memory\n",
        "        max_gpu_memory_gb = round(total_memory / (1024 ** 3), 2)  # Convert to GB and round to 2 decimal places\n",
        "        # print(f\"Maximum GPU memory available: {max_gpu_memory_gb} GB\")\n",
        "        return max_gpu_memory_gb\n",
        "    else:\n",
        "        print(\"CUDA is not available.\")\n",
        "        return None\n",
        "\n",
        "def is_gpu_memory_over_limit(limit_gb=14.5):\n",
        "    limit_gb=get_max_gpu_memory()-0.60\n",
        "    if limit_gb==None:\n",
        "      return False\n",
        "    # Run nvidia-smi and capture the output\n",
        "    result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader'],\n",
        "                            stdout=subprocess.PIPE, text=True)\n",
        "\n",
        "    # Split the result into lines (for each GPU if there are multiple)\n",
        "    memory_used_mb_list = result.stdout.strip().splitlines()\n",
        "\n",
        "    # Convert memory used from MB to GB and check each GPU's memory usage\n",
        "    for i, memory_used_mb in enumerate(memory_used_mb_list):\n",
        "        memory_used_gb = int(memory_used_mb) / 1024.0\n",
        "        # print(f\"GPU {i}: Current memory allocated: {memory_used_gb:.2f} GB\")\n",
        "        if memory_used_gb > limit_gb:\n",
        "            # print(f\"GPU {i} memory usage exceeds {limit_gb} GB.\")\n",
        "            return True\n",
        "\n",
        "    # print(\"GPU memory usage is within safe limits.\")\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def is_audio_duration_greater_than(audio_path, max_duration):\n",
        "    \"\"\"Check if audio duration is greater than max_duration.\"\"\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "        duration = len(audio) / 1000  # Duration in seconds\n",
        "        return duration > max_duration\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading audio file: {e}\")\n",
        "        return False\n",
        "\n",
        "def trim_and_convert_audio(input_audio_path, max_duration=30):\n",
        "    \"\"\"Trim audio to max_duration and convert to 16,000 Hz.\"\"\"\n",
        "    global base_path,reference_folder\n",
        "\n",
        "\n",
        "    audio = AudioSegment.from_file(input_audio_path)\n",
        "    trimmed_audio = audio[:max_duration * 1000] if len(audio) / 1000 > max_duration else audio\n",
        "    # trimmed_audio = trimmed_audio.set_frame_rate(24000)\n",
        "\n",
        "    # Generate output file name\n",
        "    base_name = os.path.splitext(os.path.basename(input_audio_path))[0]\n",
        "    output_file = f\"{reference_folder}/{base_name}_final.wav\"\n",
        "    trimmed_audio.export(output_file, format=\"wav\")\n",
        "\n",
        "    return output_file\n",
        "\n",
        "def process_audio(reference_audio, max_duration=15):\n",
        "    global reference_folder\n",
        "    \"\"\"Process audio: trim if longer than max_duration and ensure 16,000 Hz.\"\"\"\n",
        "    if is_audio_duration_greater_than(reference_audio, max_duration):\n",
        "        return trim_and_convert_audio(reference_audio, max_duration)\n",
        "\n",
        "    # If audio is less than or equal to max_duration, convert to 16,000 Hz\n",
        "    audio = AudioSegment.from_file(reference_audio)\n",
        "    # audio = audio.set_frame_rate(24000)\n",
        "\n",
        "    # Generate output file name\n",
        "    base_name = os.path.splitext(os.path.basename(reference_audio))[0]\n",
        "    output_file = f\"{reference_folder}/{base_name}_final.wav\"\n",
        "    audio.export(output_file, format=\"wav\")\n",
        "\n",
        "    return output_file\n",
        "\n",
        "def clean_file_name(file_path):\n",
        "    # Get the base file name and extension\n",
        "    file_name = os.path.basename(file_path)\n",
        "    file_name, file_extension = os.path.splitext(file_name)\n",
        "\n",
        "    # Replace non-alphanumeric characters with an underscore\n",
        "    cleaned = re.sub(r'[^a-zA-Z\\d]+', '_', file_name)\n",
        "\n",
        "    # Remove any multiple underscores\n",
        "    clean_file_name = re.sub(r'_+', '_', cleaned).strip('_')\n",
        "\n",
        "    # Generate a random UUID for uniqueness\n",
        "    random_uuid = uuid.uuid4().hex[:6]\n",
        "\n",
        "    # Combine cleaned file name with the original extension\n",
        "    clean_file_path = os.path.join(os.path.dirname(file_path), clean_file_name + f\"_{random_uuid}\" + file_extension)\n",
        "\n",
        "    return clean_file_path\n",
        "\n",
        "\n",
        "def tts_file_name(text):\n",
        "    global save_audio_folder\n",
        "    if text.endswith(\".\"):\n",
        "        text = text[:-1]\n",
        "    text = text.lower()\n",
        "    text = text.strip()\n",
        "    text = text.replace(\" \",\"_\")\n",
        "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
        "    file_name = f\"{save_audio_folder}/{truncated_text}.wav\"\n",
        "    file_name=clean_file_name(file_name)\n",
        "    return file_name\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def merge_audio(audio_list, save_path):\n",
        "    # Initialize an empty audio segment\n",
        "    merged_audio = AudioSegment.empty()\n",
        "\n",
        "    # Loop through the list of audio files\n",
        "    for audio_file in audio_list:\n",
        "        # Load each audio file\n",
        "        audio_segment = AudioSegment.from_wav(audio_file)\n",
        "        # Append to the merged audio segment\n",
        "        merged_audio += audio_segment\n",
        "\n",
        "    # Export the merged audio to the specified save path\n",
        "    merged_audio.export(save_path, format=\"wav\")\n",
        "\n",
        "def chunks_sentences(paragraph, join_limit=1):\n",
        "    sentences = sent_tokenize(paragraph)\n",
        "    # Initialize an empty list to store the new sentences\n",
        "    new_sentences = []\n",
        "\n",
        "    # Iterate through the list of sentences in steps of 'join_limit'\n",
        "    for i in range(0, len(sentences), join_limit):\n",
        "        # Join the sentences with a space between them\n",
        "        new_sentence = ' '.join(sentences[i:i + join_limit])\n",
        "        new_sentences.append(new_sentence)\n",
        "    return new_sentences\n",
        "\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2X3Ijdf7zv5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title load Model\n",
        "import os\n",
        "os.chdir(project_path)\n",
        "\n",
        "import gc\n",
        "import time\n",
        "import torch\n",
        "import safetensors\n",
        "import soundfile as sf\n",
        "from models.tts.maskgct.maskgct_utils import *\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "import shutil\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# Define global variables for models\n",
        "semantic_model, semantic_codec, codec_encoder, codec_decoder, t2s_model = None, None, None, None, None\n",
        "s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std = None, None, None, None\n",
        "whisper_pipe,whisper_model=None,None\n",
        "semantic_code_ckpt,codec_encoder_ckpt,codec_decoder_ckpt,t2s_model_ckpt,s2a_1layer_ckpt,s2a_full_ckpt\n",
        "\n",
        "def clear_model_cache():\n",
        "    \"\"\"Clear global variables and GPU memory.\"\"\"\n",
        "    global semantic_model, semantic_codec, codec_encoder, codec_decoder\n",
        "    global t2s_model, s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std\n",
        "    global whisper_pipe, whisper_model\n",
        "\n",
        "    # List of all global model variables\n",
        "    model_vars = [\n",
        "        \"semantic_model\", \"semantic_codec\", \"codec_encoder\", \"codec_decoder\",\n",
        "        \"t2s_model\", \"s2a_model_1layer\", \"s2a_model_full\", \"semantic_mean\", \"semantic_std\",\n",
        "        \"whisper_pipe\", \"whisper_model\"\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Delete and set each variable to None\n",
        "        for var in model_vars:\n",
        "            # print(f\"Variable: {var} before clearing: {globals()[var]}\")  # Print before clearing\n",
        "            if globals()[var] is not None:\n",
        "                del globals()[var]\n",
        "                globals()[var] = None\n",
        "            # print(f\"Variable: {var} after clearing: {globals()[var]}\")  # Print after clearing\n",
        "\n",
        "        # Clear Python garbage and GPU cache\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error while clearing cache: {e}\")  # Print any error that occurs\n",
        "\n",
        "\n",
        "# Load Whisper model\n",
        "\n",
        "def load_model():\n",
        "    \"\"\"Load models into GPU memory, clearing old models first.\"\"\"\n",
        "    global semantic_model, semantic_codec, codec_encoder, codec_decoder\n",
        "    global t2s_model, s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std\n",
        "    global whisper_pipe,whisper_model\n",
        "    global semantic_code_ckpt,codec_encoder_ckpt,codec_decoder_ckpt,t2s_model_ckpt,s2a_1layer_ckpt,s2a_full_ckpt\n",
        "    # Clear any previously loaded models from memory\n",
        "    clear_model_cache()\n",
        "    time.sleep(5)  # Optional delay to ensure memory is fully cleared\n",
        "    # Load configurations\n",
        "    cfg_path = \"./models/tts/maskgct/config/maskgct.json\"\n",
        "    cfg = load_config(cfg_path)\n",
        "\n",
        "    # Load models\n",
        "    semantic_model, semantic_mean, semantic_std = build_semantic_model(device)\n",
        "    semantic_codec = build_semantic_codec(cfg.model.semantic_codec, device)\n",
        "    codec_encoder, codec_decoder = build_acoustic_codec(cfg.model.acoustic_codec, device)\n",
        "    t2s_model = build_t2s_model(cfg.model.t2s_model, device)\n",
        "    s2a_model_1layer = build_s2a_model(cfg.model.s2a_model.s2a_1layer, device)\n",
        "    s2a_model_full = build_s2a_model(cfg.model.s2a_model.s2a_full, device)\n",
        "\n",
        "    # Load checkpoints\n",
        "    safetensors.torch.load_model(semantic_codec, semantic_code_ckpt)\n",
        "    safetensors.torch.load_model(codec_encoder, codec_encoder_ckpt)\n",
        "    safetensors.torch.load_model(codec_decoder, codec_decoder_ckpt)\n",
        "    safetensors.torch.load_model(t2s_model, t2s_model_ckpt)\n",
        "    safetensors.torch.load_model(s2a_model_1layer, s2a_1layer_ckpt)\n",
        "    safetensors.torch.load_model(s2a_model_full, s2a_full_ckpt)\n",
        "\n",
        "    #load Whisper\n",
        "    model_id = \"openai/whisper-large-v3-turbo\"\n",
        "    whisper_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "        model_id, torch_dtype=torch.float16, low_cpu_mem_usage=True, use_safetensors=True\n",
        "    )\n",
        "    whisper_model.to(device)\n",
        "    processor = AutoProcessor.from_pretrained(model_id)\n",
        "    whisper_pipe = pipeline(\n",
        "        \"automatic-speech-recognition\",\n",
        "        model=whisper_model,\n",
        "        tokenizer=processor.tokenizer,\n",
        "        feature_extractor=processor.feature_extractor,\n",
        "        torch_dtype=torch.float16,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    return (semantic_model, semantic_codec, codec_encoder, codec_decoder,\n",
        "            t2s_model, s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std,\n",
        "            whisper_model,whisper_pipe)\n",
        "\n",
        "\n",
        "\n",
        "def voice_clone(reference_path, text,duration=None):\n",
        "    global semantic_model, semantic_codec, codec_encoder, codec_decoder\n",
        "    global t2s_model, s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std\n",
        "    global whisper_model, whisper_pipe\n",
        "    prompt_wav_path = process_audio(reference_path, max_duration=15)\n",
        "    if is_gpu_memory_over_limit():\n",
        "        print(\"Loading models due to GPU memory limit\")\n",
        "        (\n",
        "            semantic_model, semantic_codec, codec_encoder, codec_decoder,\n",
        "            t2s_model, s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std,\n",
        "            whisper_model, whisper_pipe\n",
        "        ) = load_model()\n",
        "\n",
        "    print(\"Processing reference audio:\", prompt_wav_path)\n",
        "\n",
        "    # Get the prompt text from the reference audio\n",
        "    try:\n",
        "        prompt_text = whisper_pipe(prompt_wav_path)['text'].strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error during transcription: {e}\")\n",
        "        return None\n",
        "\n",
        "    print(\"Extracted prompt text:\", prompt_text)\n",
        "\n",
        "    # Set the target text\n",
        "    target_text = text\n",
        "\n",
        "    # Check if the prompt_text and target_text are not empty\n",
        "    if not prompt_text or not target_text:\n",
        "        print(\"Prompt text or target text is empty.\")\n",
        "        return None\n",
        "\n",
        "    # Create the inference pipeline\n",
        "    maskgct_inference_pipeline = MaskGCT_Inference_Pipeline(\n",
        "        semantic_model,\n",
        "        semantic_codec,\n",
        "        codec_encoder,\n",
        "        codec_decoder,\n",
        "        t2s_model,\n",
        "        s2a_model_1layer,\n",
        "        s2a_model_full,\n",
        "        semantic_mean,\n",
        "        semantic_std,\n",
        "        device,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        recovered_audio = maskgct_inference_pipeline.maskgct_inference(\n",
        "            prompt_wav_path, prompt_text, target_text, \"en\", \"en\", target_len=duration\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error during inference: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Save the output audio\n",
        "    save_path = tts_file_name(text)\n",
        "    sf.write(save_path, recovered_audio, 24000)\n",
        "    print(f\"Audio saved to: {save_path}\")\n",
        "    return save_path\n",
        "\n",
        "\n",
        "\n",
        "def voice_clone_long_text(reference_audio_path,text,input_duration):\n",
        "  global base_path\n",
        "  audio_list=[]\n",
        "  temp_folder=f\"{base_path}/clone_voice\"\n",
        "  if os.path.exists(temp_folder):\n",
        "    shutil.rmtree(temp_folder)\n",
        "  os.mkdir(temp_folder)\n",
        "  sentences=chunks_sentences(text,join_limit=2)\n",
        "  for index,sentence in enumerate(sentences):\n",
        "    temp_path=voice_clone(reference_audio_path, sentence,duration=input_duration)\n",
        "    temp_file=f\"{temp_folder}/{index}.wav\"\n",
        "    shutil.move(temp_path,temp_file)\n",
        "    audio_list.append(temp_file)\n",
        "  cloned_voice_path=tts_file_name(text)\n",
        "  merge_audio(audio_list, cloned_voice_path)\n",
        "  return cloned_voice_path\n",
        "\n",
        "def gradio_app(reference_audio_path,text,input_duration,large_text):\n",
        "  if input_duration==-1 or input_duration==0:\n",
        "    Duration=None\n",
        "  else:\n",
        "    Duration=input_duration\n",
        "  if large_text:\n",
        "    cloned_voice_path=voice_clone_long_text(reference_audio_path,text,Duration)\n",
        "  else:\n",
        "    cloned_voice_path=voice_clone(reference_audio_path, text,duration=Duration)\n",
        "  return cloned_voice_path\n",
        "\n",
        "\n",
        "\n",
        "# Call the function\n",
        "# voice_clone(\"/content/reference.wav\", \"hi how are you guys\",duration=None)\n",
        "\n",
        "\n",
        "# Load models for the first time, clearing any old models\n",
        "(\n",
        "    semantic_model, semantic_codec, codec_encoder, codec_decoder,\n",
        "    t2s_model, s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std,\n",
        "    whisper_model,whisper_pipe\n",
        ") = load_model()\n",
        "\n",
        "\n",
        "reference_folder = f\"{base_path}/trim_audio\"\n",
        "save_audio_folder=f\"{base_path}/clone_voice\"\n",
        "os.makedirs(reference_folder, exist_ok=True)\n",
        "os.makedirs(save_audio_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eXeccCJhyYoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Using Gradio Interface\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "gradio_inputs=[gr.Audio(label=\"Reference Audio\", type=\"filepath\"),\n",
        "               gr.Textbox(label=\"Text to Generate\",lines=3),\n",
        "               gr.Number(label=\"Target Duration (in seconds), if the target duration is less than 0, the system will estimate a duration.\", value=-1),\n",
        "               gr.Checkbox(label=\"Long Text ?\",value=False)\n",
        "              ]\n",
        "gradio_outputs=[gr.Audio(label=\"Generated Audio\")]\n",
        "demo = gr.Interface(fn=gradio_app, inputs=gradio_inputs,outputs=gradio_outputs , title=\"MaskGCT TTS English Demo \")\n",
        "demo.launch(allowed_paths=[f\"{base_path}/clone_voice\"],debug=False,share=True)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gUWqYldo9Epu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run From Colab Cell"
      ],
      "metadata": {
        "id": "edbK08QVFEwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Uplaod Reference Audio File\n",
        "import os\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def upload_audio():\n",
        "    upload_folder = f\"{base_path}/user_upload\"\n",
        "\n",
        "    # Ensure the upload folder exists\n",
        "    os.makedirs(upload_folder, exist_ok=True)\n",
        "\n",
        "    # Change to the upload directory\n",
        "    os.chdir(upload_folder)\n",
        "\n",
        "    # Upload the files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Switch back to the original install directory (ensure install_path is defined)\n",
        "    os.chdir(project_path)\n",
        "\n",
        "    audio_name_list = []\n",
        "\n",
        "    for fn in uploaded.keys():\n",
        "        file_path = f\"{upload_folder}/{fn}\"\n",
        "        save_file_path = clean_file_name(file_path)\n",
        "\n",
        "        # Rename the file with cleaned file name\n",
        "        os.rename(file_path, save_file_path)\n",
        "        audio_name_list.append(save_file_path)\n",
        "\n",
        "    # Filter audio files based on valid audio extensions\n",
        "    audio_extensions = ('.wav', '.mp3')\n",
        "    valid_audio_files = [f for f in audio_name_list if f.lower().endswith(audio_extensions)]\n",
        "\n",
        "    # Clear the output (for Google Colab)\n",
        "    clear_output()\n",
        "\n",
        "    if valid_audio_files:\n",
        "        # Return the first valid audio file found\n",
        "        return valid_audio_files[0]\n",
        "    else:\n",
        "        # Print message if no valid audio files were uploaded\n",
        "        print(\"Please upload an audio file.\")\n",
        "        return None\n",
        "upload_audio()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UoLKIPvL-PxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TTS_Duration: 0 mean None , the system will estimate a duration.\n"
      ],
      "metadata": {
        "id": "vnVZbmbfGddG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate TTS\n",
        "Reference_Audio_Path= '/content/anime.mp3'  # @param {type: \"string\"}\n",
        "Text_to_Generate= \"What kind of story would you like? Fantasy, sci-fi, adventure, or maybe something heartwarming or mysterious? And do you want it to be short or longer? Let me know any details you want, and I'll dive right in!\"  # @param {type: \"string\"}\n",
        "TTS_Duration = 0  # @param {type: \"number\"}\n",
        "Large_Text = 0  # @param {type: \"boolean\"}\n",
        "cloned_voice_path=gradio_app(Reference_Audio_Path,Text_to_Generate,TTS_Duration,Large_Text)\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(f\"TTS Save at {cloned_voice_path}\")\n",
        "from IPython.display import Audio\n",
        "Audio(cloned_voice_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "t_zs3Rp9-nOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Cloned Voice\n",
        "from google.colab import files\n",
        "files.download(cloned_voice_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yN1GK_s9GOcV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
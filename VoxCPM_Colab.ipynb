{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ğŸ·ï¸ **Credits & License**\n",
        "\n",
        "* ğŸ”— [VoxCPM GitHub Repository](https://github.com/OpenBMB/VoxCPM)\n",
        "* ğŸ¤— [VoxCPM-0.5B on Hugging Face](https://huggingface.co/openbmb/VoxCPM-0.5B)\n",
        "* ğŸ“„ **License**: Provided under the [Apache License 2.0](https://github.com/OpenBMB/VoxCPM/blob/main/LICENSE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### âš ï¸ **Usage Disclaimer**\n",
        "\n",
        "Use of this voice cloning model is subject to strict ethical and legal standards. By using this tool, you agree **not to** engage in any of the following prohibited activities:\n",
        "\n",
        "* **Fraud or Deception**: Using cloned voices to create misleading or fraudulent content.\n",
        "* **Impersonation**: Replicating someoneâ€™s voice without their explicit permission, especially for malicious, harmful, or deceptive purposes.\n",
        "* **Illegal Activities**: Employing the model in any manner that violates local, national, or international laws and regulations.\n",
        "* **Harmful Content Generation**: Creating offensive, defamatory, or unethical material, including content that spreads misinformation or causes harm.\n",
        "\n",
        "> âš–ï¸ **Legal Responsibility**\n",
        "> The developers of this tool disclaim all liability for misuse. **Users bear full responsibility** for ensuring that their usage complies with all applicable laws, regulations, and ethical guidelines.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ga55Ee4b2en_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "4WIm752XP38f"
      },
      "outputs": [],
      "source": [
        "#@title Install VoxCPM\n",
        "%cd /content/\n",
        "!git clone https://github.com/OpenBMB/VoxCPM.git\n",
        "%cd ./VoxCPM\n",
        "!pip install -e .\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5_FpQxXXcIE",
        "outputId": "5b293a34-7bae-4617-c36c-00bb90e5dcfd",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/VoxCPM/app.py\n"
          ]
        }
      ],
      "source": [
        "#@title Add gradio share on app.py\n",
        "%%writefile /content/VoxCPM/app.py\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import gradio as gr\n",
        "import spaces\n",
        "from typing import Optional, Tuple\n",
        "from funasr import AutoModel\n",
        "from pathlib import Path\n",
        "os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "if os.environ.get(\"HF_REPO_ID\", \"\").strip() == \"\":\n",
        "    os.environ[\"HF_REPO_ID\"] = \"openbmb/VoxCPM-0.5B\"\n",
        "\n",
        "import voxcpm\n",
        "\n",
        "\n",
        "class VoxCPMDemo:\n",
        "    def __init__(self) -> None:\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"ğŸš€ Running on device: {self.device}\")\n",
        "\n",
        "        # ASR model for prompt text recognition\n",
        "        self.asr_model_id = \"iic/SenseVoiceSmall\"\n",
        "        self.asr_model: Optional[AutoModel] = AutoModel(\n",
        "            model=self.asr_model_id,\n",
        "            disable_update=True,\n",
        "            log_level='DEBUG',\n",
        "            device=\"cuda:0\" if self.device == \"cuda\" else \"cpu\",\n",
        "        )\n",
        "\n",
        "        # TTS model (lazy init)\n",
        "        self.voxcpm_model: Optional[voxcpm.VoxCPM] = None\n",
        "        self.default_local_model_dir = \"./models/VoxCPM-0.5B\"\n",
        "\n",
        "    # ---------- Model helpers ----------\n",
        "    def _resolve_model_dir(self) -> str:\n",
        "        \"\"\"\n",
        "        Resolve model directory:\n",
        "        1) Use local checkpoint directory if exists\n",
        "        2) If HF_REPO_ID env is set, download into models/{repo}\n",
        "        3) Fallback to 'models'\n",
        "        \"\"\"\n",
        "        if os.path.isdir(self.default_local_model_dir):\n",
        "            return self.default_local_model_dir\n",
        "\n",
        "        repo_id = os.environ.get(\"HF_REPO_ID\", \"\").strip()\n",
        "        if len(repo_id) > 0:\n",
        "            target_dir = os.path.join(\"models\", repo_id.replace(\"/\", \"__\"))\n",
        "            if not os.path.isdir(target_dir):\n",
        "                try:\n",
        "                    from huggingface_hub import snapshot_download  # type: ignore\n",
        "                    os.makedirs(target_dir, exist_ok=True)\n",
        "                    print(f\"Downloading model from HF repo '{repo_id}' to '{target_dir}' ...\")\n",
        "                    snapshot_download(repo_id=repo_id, local_dir=target_dir, local_dir_use_symlinks=False)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: HF download failed: {e}. Falling back to 'data'.\")\n",
        "                    return \"models\"\n",
        "            return target_dir\n",
        "        return \"models\"\n",
        "\n",
        "    def get_or_load_voxcpm(self) -> voxcpm.VoxCPM:\n",
        "        if self.voxcpm_model is not None:\n",
        "            return self.voxcpm_model\n",
        "        print(\"Model not loaded, initializing...\")\n",
        "        model_dir = self._resolve_model_dir()\n",
        "        print(f\"Using model dir: {model_dir}\")\n",
        "        self.voxcpm_model = voxcpm.VoxCPM(voxcpm_model_path=model_dir)\n",
        "        print(\"Model loaded successfully.\")\n",
        "        return self.voxcpm_model\n",
        "\n",
        "    # ---------- Functional endpoints ----------\n",
        "    def prompt_wav_recognition(self, prompt_wav: Optional[str]) -> str:\n",
        "        if prompt_wav is None:\n",
        "            return \"\"\n",
        "        res = self.asr_model.generate(input=prompt_wav, language=\"auto\", use_itn=True)\n",
        "        text = res[0][\"text\"].split('|>')[-1]\n",
        "        return text\n",
        "\n",
        "    def generate_tts_audio(\n",
        "        self,\n",
        "        text_input: str,\n",
        "        prompt_wav_path_input: Optional[str] = None,\n",
        "        prompt_text_input: Optional[str] = None,\n",
        "        cfg_value_input: float = 2.0,\n",
        "        inference_timesteps_input: int = 10,\n",
        "        do_normalize: bool = True,\n",
        "        denoise: bool = True,\n",
        "    ) -> Tuple[int, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Generate speech from text using VoxCPM; optional reference audio for voice style guidance.\n",
        "        Returns (sample_rate, waveform_numpy)\n",
        "        \"\"\"\n",
        "        current_model = self.get_or_load_voxcpm()\n",
        "\n",
        "        text = (text_input or \"\").strip()\n",
        "        if len(text) == 0:\n",
        "            raise ValueError(\"Please input text to synthesize.\")\n",
        "\n",
        "        prompt_wav_path = prompt_wav_path_input if prompt_wav_path_input else None\n",
        "        prompt_text = prompt_text_input if prompt_text_input else None\n",
        "\n",
        "        print(f\"Generating audio for text: '{text[:60]}...'\")\n",
        "        wav = current_model.generate(\n",
        "            text=text,\n",
        "            prompt_text=prompt_text,\n",
        "            prompt_wav_path=prompt_wav_path,\n",
        "            cfg_value=float(cfg_value_input),\n",
        "            inference_timesteps=int(inference_timesteps_input),\n",
        "            normalize=do_normalize,\n",
        "            denoise=denoise,\n",
        "        )\n",
        "        return (16000, wav)\n",
        "\n",
        "\n",
        "# ---------- UI Builders ----------\n",
        "\n",
        "def create_demo_interface(demo: VoxCPMDemo):\n",
        "    \"\"\"Build the Gradio UI for VoxCPM demo.\"\"\"\n",
        "    # static assets (logo path)\n",
        "    gr.set_static_paths(paths=[Path.cwd().absolute()/\"assets\"])\n",
        "\n",
        "    with gr.Blocks(\n",
        "        theme=gr.themes.Soft(\n",
        "            primary_hue=\"blue\",\n",
        "            secondary_hue=\"gray\",\n",
        "            neutral_hue=\"slate\",\n",
        "            font=[gr.themes.GoogleFont(\"Inter\"), \"Arial\", \"sans-serif\"]\n",
        "        ),\n",
        "        css=\"\"\"\n",
        "        .logo-container {\n",
        "            text-align: center;\n",
        "            margin: 0.5rem 0 1rem 0;\n",
        "        }\n",
        "        .logo-container img {\n",
        "            height: 80px;\n",
        "            width: auto;\n",
        "            max-width: 200px;\n",
        "            display: inline-block;\n",
        "        }\n",
        "        /* Bold accordion labels */\n",
        "        #acc_quick details > summary,\n",
        "        #acc_tips details > summary {\n",
        "            font-weight: 600 !important;\n",
        "            font-size: 1.1em !important;\n",
        "        }\n",
        "        /* Bold labels for specific checkboxes */\n",
        "        #chk_denoise label,\n",
        "        #chk_denoise span,\n",
        "        #chk_normalize label,\n",
        "        #chk_normalize span {\n",
        "            font-weight: 600;\n",
        "        }\n",
        "        \"\"\"\n",
        "    ) as interface:\n",
        "        # Header logo\n",
        "        gr.HTML('<div class=\"logo-container\"><img src=\"/gradio_api/file=assets/voxcpm_logo.png\" alt=\"VoxCPM Logo\"></div>')\n",
        "\n",
        "        # Quick Start\n",
        "        with gr.Accordion(\"ğŸ“‹ Quick Start Guide ï½œå¿«é€Ÿå…¥é—¨\", open=False, elem_id=\"acc_quick\"):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### How to Use ï½œä½¿ç”¨è¯´æ˜\n",
        "            1. **(Optional) Provide a Voice Prompt** - Upload or record an audio clip to provide the desired voice characteristics for synthesis.\n",
        "               **ï¼ˆå¯é€‰ï¼‰æä¾›å‚è€ƒå£°éŸ³** - ä¸Šä¼ æˆ–å½•åˆ¶ä¸€æ®µéŸ³é¢‘ï¼Œä¸ºå£°éŸ³åˆæˆæä¾›éŸ³è‰²ã€è¯­è°ƒå’Œæƒ…æ„Ÿç­‰ä¸ªæ€§åŒ–ç‰¹å¾\n",
        "            2. **(Optional) Enter prompt text** - If you provided a voice prompt, enter the corresponding transcript here (auto-recognition available).\n",
        "               **ï¼ˆå¯é€‰é¡¹ï¼‰è¾“å…¥å‚è€ƒæ–‡æœ¬** - å¦‚æœæä¾›äº†å‚è€ƒè¯­éŸ³ï¼Œè¯·è¾“å…¥å…¶å¯¹åº”çš„æ–‡æœ¬å†…å®¹ï¼ˆæ”¯æŒè‡ªåŠ¨è¯†åˆ«ï¼‰ã€‚\n",
        "            3. **Enter target text** - Type the text you want the model to speak.\n",
        "               **è¾“å…¥ç›®æ ‡æ–‡æœ¬** - è¾“å…¥æ‚¨å¸Œæœ›æ¨¡å‹æœ—è¯»çš„æ–‡å­—å†…å®¹ã€‚\n",
        "            4. **Generate Speech** - Click the \"Generate\" button to create your audio.\n",
        "               **ç”Ÿæˆè¯­éŸ³** - ç‚¹å‡»\"ç”Ÿæˆ\"æŒ‰é’®ï¼Œå³å¯ä¸ºæ‚¨åˆ›é€ å‡ºéŸ³é¢‘ã€‚\n",
        "            \"\"\")\n",
        "\n",
        "        # Pro Tips\n",
        "        with gr.Accordion(\"ğŸ’¡ Pro Tips ï½œä½¿ç”¨å»ºè®®\", open=False, elem_id=\"acc_tips\"):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### Prompt Speech Enhancementï½œå‚è€ƒè¯­éŸ³é™å™ª\n",
        "            - **Enable** to remove background noise for a clean, studio-like voice, with an external ZipEnhancer component.\n",
        "              **å¯ç”¨**ï¼šé€šè¿‡ ZipEnhancer ç»„ä»¶æ¶ˆé™¤èƒŒæ™¯å™ªéŸ³ï¼Œè·å¾—æ›´å¥½çš„éŸ³è´¨ã€‚\n",
        "            - **Disable** to preserve the original audio's background atmosphere.\n",
        "              **ç¦ç”¨**ï¼šä¿ç•™åŸå§‹éŸ³é¢‘çš„èƒŒæ™¯ç¯å¢ƒå£°ï¼Œå¦‚æœæƒ³å¤åˆ»ç›¸åº”å£°å­¦ç¯å¢ƒã€‚\n",
        "\n",
        "            ### Text Normalizationï½œæ–‡æœ¬æ­£åˆ™åŒ–\n",
        "            - **Enable** to process general text with an external WeTextProcessing component.\n",
        "              **å¯ç”¨**ï¼šä½¿ç”¨ WeTextProcessing ç»„ä»¶ï¼Œå¯å¤„ç†å¸¸è§æ–‡æœ¬ã€‚\n",
        "            - **Disable** to use VoxCPM's native text understanding ability. For example, it supports phonemes input ({HH AH0 L OW1}), try it!\n",
        "              **ç¦ç”¨**ï¼šå°†ä½¿ç”¨ VoxCPM å†…ç½®çš„æ–‡æœ¬ç†è§£èƒ½åŠ›ã€‚å¦‚ï¼Œæ”¯æŒéŸ³ç´ è¾“å…¥ï¼ˆå¦‚ {da4}{jia1}å¥½ï¼‰å’Œå…¬å¼ç¬¦å·åˆæˆï¼Œå°è¯•ä¸€ä¸‹ï¼\n",
        "\n",
        "            ### CFG Valueï½œCFG å€¼\n",
        "            - **Lower CFG** if the voice prompt sounds strained or expressive.\n",
        "              **è°ƒä½**ï¼šå¦‚æœæç¤ºè¯­éŸ³å¬èµ·æ¥ä¸è‡ªç„¶æˆ–è¿‡äºå¤¸å¼ ã€‚\n",
        "            - **Higher CFG** for better adherence to the prompt speech style or input text.\n",
        "              **è°ƒé«˜**ï¼šä¸ºæ›´å¥½åœ°è´´åˆæç¤ºéŸ³é¢‘çš„é£æ ¼æˆ–è¾“å…¥æ–‡æœ¬ã€‚\n",
        "\n",
        "            ### Inference Timestepsï½œæ¨ç†æ—¶é—´æ­¥\n",
        "            - **Lower** for faster synthesis speed.\n",
        "              **è°ƒä½**ï¼šåˆæˆé€Ÿåº¦æ›´å¿«ã€‚\n",
        "            - **Higher** for better synthesis quality.\n",
        "              **è°ƒé«˜**ï¼šåˆæˆè´¨é‡æ›´ä½³ã€‚\n",
        "            \"\"\")\n",
        "\n",
        "        # Main controls\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                prompt_wav = gr.Audio(\n",
        "                    sources=[\"upload\", 'microphone'],\n",
        "                    type=\"filepath\",\n",
        "                    label=\"Prompt Speech (Optional, or let VoxCPM improvise)\",\n",
        "                    value=\"./examples/example.wav\",\n",
        "                )\n",
        "                DoDenoisePromptAudio = gr.Checkbox(\n",
        "                    value=False,\n",
        "                    label=\"Prompt Speech Enhancement\",\n",
        "                    elem_id=\"chk_denoise\",\n",
        "                    info=\"We use ZipEnhancer model to denoise the prompt audio.\"\n",
        "                )\n",
        "                with gr.Row():\n",
        "                    prompt_text = gr.Textbox(\n",
        "                        value=\"Just by listening a few minutes a day, you'll be able to eliminate negative thoughts by conditioning your mind to be more positive.\",\n",
        "                        label=\"Prompt Text\",\n",
        "                        placeholder=\"Please enter the prompt text. Automatic recognition is supported, and you can correct the results yourself...\"\n",
        "                    )\n",
        "                run_btn = gr.Button(\"Generate Speech\", variant=\"primary\")\n",
        "\n",
        "            with gr.Column():\n",
        "                cfg_value = gr.Slider(\n",
        "                    minimum=1.0,\n",
        "                    maximum=3.0,\n",
        "                    value=2.0,\n",
        "                    step=0.1,\n",
        "                    label=\"CFG Value (Guidance Scale)\",\n",
        "                    info=\"Higher values increase adherence to prompt, lower values allow more creativity\"\n",
        "                )\n",
        "                inference_timesteps = gr.Slider(\n",
        "                    minimum=4,\n",
        "                    maximum=30,\n",
        "                    value=10,\n",
        "                    step=1,\n",
        "                    label=\"Inference Timesteps\",\n",
        "                    info=\"Number of inference timesteps for generation (higher values may improve quality but slower)\"\n",
        "                )\n",
        "                with gr.Row():\n",
        "                    text = gr.Textbox(\n",
        "                        value=\"VoxCPM is an innovative end-to-end TTS model from ModelBest, designed to generate highly realistic speech.\",\n",
        "                        label=\"Target Text\",\n",
        "                    )\n",
        "                with gr.Row():\n",
        "                    DoNormalizeText = gr.Checkbox(\n",
        "                        value=False,\n",
        "                        label=\"Text Normalization\",\n",
        "                        elem_id=\"chk_normalize\",\n",
        "                        info=\"We use wetext library to normalize the input text.\"\n",
        "                    )\n",
        "                audio_output = gr.Audio(label=\"Output Audio\")\n",
        "\n",
        "        # Wiring\n",
        "        run_btn.click(\n",
        "            fn=demo.generate_tts_audio,\n",
        "            inputs=[text, prompt_wav, prompt_text, cfg_value, inference_timesteps, DoNormalizeText, DoDenoisePromptAudio],\n",
        "            outputs=[audio_output],\n",
        "            show_progress=True,\n",
        "            api_name=\"generate\",\n",
        "        )\n",
        "        prompt_wav.change(fn=demo.prompt_wav_recognition, inputs=[prompt_wav], outputs=[prompt_text])\n",
        "\n",
        "    return interface\n",
        "\n",
        "\n",
        "# def run_demo(server_name: str = \"localhost\", server_port: int = 7860, show_error: bool = True):\n",
        "#     demo = VoxCPMDemo()\n",
        "#     interface = create_demo_interface(demo)\n",
        "#     # Recommended to enable queue on Spaces for better throughput\n",
        "#     interface.queue(max_size=10).launch(server_name=server_name, server_port=server_port, show_error=show_error)\n",
        "\n",
        "\n",
        "import click\n",
        "@click.command()\n",
        "@click.option(\"--debug\", is_flag=True, default=False, help=\"Enable debug mode.\")\n",
        "@click.option(\"--share\", is_flag=True, default=False, help=\"Enable sharing of the interface.\")\n",
        "def run_demo(share,debug):\n",
        "    demo = VoxCPMDemo()\n",
        "    interface = create_demo_interface(demo)\n",
        "    interface.queue(max_size=10).launch(share=share,debug=debug)\n",
        "if __name__ == \"__main__\":\n",
        "    run_demo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVx-NfYeRS25"
      },
      "outputs": [],
      "source": [
        "%cd /content/VoxCPM\n",
        "!python app.py --share --debug"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}